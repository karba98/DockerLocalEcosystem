## Dockerfile.fooocus-gpu
## Construye un contenedor para Fooocus intentando soportar GPUs recientes.
## NOTA: Si tu GPU (RTX 50xx / sm_120) aún no está soportada por PyTorch precompilado,
## tendrás que usar modo CPU (establece CUDA_VISIBLE_DEVICES="") o compilar PyTorch desde fuente.

## Imagen base actualizada a CUDA 12.8 runtime para soporte RTX 50xx
FROM nvidia/cuda:12.8.0-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive \
    PIP_NO_CACHE_DIR=1 \
    PYTHONUNBUFFERED=1 \
    GRADIO_SERVER_PORT=8084 \
    HF_HUB_DISABLE_SYMLINKS_WARNING=1 \
    PYTORCH_ENABLE_MPS_FALLBACK=1 \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility \
    TORCH_EXTRA_INDEX=https://download.pytorch.org/whl/cu128

ARG TORCH_FORCE_VERSION="torch==2.7.0+cu128"
ARG INSTALL_TOOLKIT=0

WORKDIR /app

## Dependencias del sistema (python, build tools) y clon del repositorio
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential ca-certificates curl git python3 python3-dev python3-pip python3-venv wget \
        && ln -sf /usr/bin/python3 /usr/local/bin/python \
        && if [ "$INSTALL_TOOLKIT" = "1" ]; then \
                 wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb && \
                 dpkg -i cuda-keyring_1.1-1_all.deb && rm cuda-keyring_1.1-1_all.deb && \
                 apt-get update && apt-get install -y --no-install-recommends cuda-toolkit-12-8; \
             fi \
        && git clone https://github.com/lllyasviel/Fooocus.git fooocus \
        && rm -rf /var/lib/apt/lists/* \
        && echo "Repositorio Fooocus clonado"

WORKDIR /app/fooocus

## Instalar Torch específico cu128 (RTX 50xx) y dependencias. Si falla, continuar y luego Fooocus intentará instalar.
RUN python -m pip install --upgrade pip \
 && if [ -n "$TORCH_FORCE_VERSION" ]; then \
            python -m pip install --force-reinstall "$TORCH_FORCE_VERSION" --extra-index-url "$TORCH_EXTRA_INDEX" || echo "[WARN] Falló instalación forzada de Torch cu128"; \
        fi \
 && if [ -f requirements_versions.txt ]; then python -m pip install -r requirements_versions.txt; fi \
 && python -m pip install Pillow accelerate fastapi safetensors transformers uvicorn

# (Opcional) Forzar CPU temporal si tu GPU no está soportada todavía:
# ENV CUDA_VISIBLE_DEVICES=""

# Info de versión Torch instalada (debug)
RUN python - <<'PY'
import torch, sys
print('Torch version:', getattr(torch,'__version__','(no torch)'))
print('CUDA available:', torch.cuda.is_available())
print('CUDA device count:', torch.cuda.device_count())
PY

# Exponer puerto
EXPOSE 8084

# Comando real: utilizar launch.py (prepara entorno y lanza Gradio) y escuchar en 0.0.0.0
ENV CLI_ARGS="--listen 0.0.0.0 --port 8084"

# Copiar script de arranque al final para permitir cambios sin reconstruir dependencias pesadas
COPY start.sh /app/start.sh
RUN set -eux; \
    chmod 755 /app/start.sh; \
    sed -n '1,5p' /app/start.sh >/dev/null

CMD ["/app/start.sh"]
